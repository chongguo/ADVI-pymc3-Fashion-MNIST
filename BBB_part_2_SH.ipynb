{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BBB Project Part 2\n",
    "===\n",
    "\n",
    "- Shows performance of bayes by backprop, a method using Variational Inference on a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local folders to path\n",
    "import os, sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import mode\n",
    "from pymc3.theanof import set_tt_rng, MRG_RandomStreams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMC3  v3.5\n",
      "Theano v1.0.3\n"
     ]
    }
   ],
   "source": [
    "print('PyMC3  v{}\\nTheano v{}'.format(pm.__version__,theano.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "pm.set_tt_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid warnings on batches below\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorflow to import image datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "reshape_train_imgs = lambda img : img.reshape(img.shape[0],-1)\n",
    "imgvec2img = lambda vec : vec.reshape((np.sqrt(vec.shape[0]).astype(int),np.sqrt(vec.shape[0]).astype(int)))\n",
    "floatX = theano.config.floatX\n",
    "\n",
    "dataset = 'fashion_mnist'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train,X_test = reshape_train_imgs(X_train),reshape_train_imgs(X_test)\n",
    "    label_dict = OrderedDict({i:str(i) for i in range(10)})\n",
    "    \n",
    "    X_train = X_train.astype(floatX)/255\n",
    "    y_train = y_train.astype(np.int)\n",
    "    X_test = X_test.astype(floatX)/255\n",
    "    y_test = y_test.astype(np.int)\n",
    "    \n",
    "    n_output = len(label_dict)\n",
    "    \n",
    "elif dataset == 'fashion_mnist':\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    X_train,X_test = reshape_train_imgs(X_train),reshape_train_imgs(X_test)\n",
    "    label_dict = OrderedDict({0: 'T-shirt/top',\n",
    "                              1: 'Trouser',\n",
    "                              2: 'Pullover',\n",
    "                              3: 'Dress',\n",
    "                              4: 'Coat',\n",
    "                              5: 'Sandal',\n",
    "                              6: 'Shirt',\n",
    "                              7: 'Sneaker',\n",
    "                              8: 'Bag',\n",
    "                              9: 'Ankle boot'})\n",
    "    X_train = X_train.astype(floatX)/255\n",
    "    y_train = y_train.astype(np.int)\n",
    "    X_test = X_test.astype(floatX)/255\n",
    "    y_test = y_test.astype(np.int)\n",
    "    \n",
    "    n_output = len(label_dict)\n",
    "\n",
    "(n_train,n_input) = X_train.shape\n",
    "print(\"N Input for {} = {}\".format(dataset,n_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `%load` magic here to load `bbb_nn.py`. Delete are re-run a cell as below for updates:\n",
    "```python\n",
    "%load bbb_nn.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load bbb_nn.py\n",
    "def construct_nn(ann_input, ann_output, n_input, n_output, n_train, n_hidden_1=64, n_hidden_2=32):\n",
    "    # backwards compatibility\n",
    "    return construct_nn_2lay(ann_input, ann_output, n_input, n_output, n_train, n_hidden_1, n_hidden_2)\n",
    "\n",
    "def construct_nn_1lay(ann_input, ann_output, n_input, n_output, n_train, n_hidden_1=64):\n",
    "    \n",
    "    # Initialize random weights between each layer\n",
    "    init_w_in_1 = np.random.randn(n_input, n_hidden_1).astype(theano.config.floatX)\n",
    "    init_b_1 = np.random.randn(n_hidden_1).astype(theano.config.floatX)\n",
    "    init_w_1_out = np.random.randn(n_hidden_1, n_output).astype(theano.config.floatX)\n",
    "    \n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to first hidden layer\n",
    "        w_in_1 = pm.Normal('w_in_1', mu=0, sd=0.5, shape=(n_input, n_hidden_1), testval=init_w_in_1)\n",
    "        \n",
    "        # Bias in first layer\n",
    "        b_1 = pm.Normal('b_1',mu=0, sd=0.5, shape=(n_hidden_1), testval=init_b_1)\n",
    "        \n",
    "        # Weights from 1st hidden layer to output layer\n",
    "        w_1_out = pm.Normal('w_1_out',mu=0, sd=0.5, shape=(n_hidden_1, n_output), testval=init_w_1_out)\n",
    "        \n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.Deterministic('act_1',var=pm.math.tanh(pm.math.dot(ann_input,w_in_1)+b_1))        \n",
    "        \n",
    "        # Softmax is required at last layer\n",
    "        act_out = pm.Deterministic('act_out',var=tt.nnet.softmax(pm.math.dot(act_1,w_1_out)))\n",
    "        \n",
    "        # Classification\n",
    "        out = pm.Categorical('out',act_out,observed=ann_output,total_size=n_train)\n",
    "        \n",
    "    return neural_network\n",
    "\n",
    "def construct_nn_2lay(ann_input, ann_output, n_input, n_output, n_train, n_hidden_1=64, n_hidden_2=32):\n",
    "    \n",
    "    # Initialize random weights between each layer\n",
    "    init_w_1 = np.random.randn(n_input, n_hidden_1).astype(theano.config.floatX)\n",
    "    init_w_2 = np.random.randn(n_hidden_1, n_hidden_2).astype(theano.config.floatX)\n",
    "    init_out = np.random.randn(n_hidden_2, n_output).astype(theano.config.floatX)\n",
    "    \n",
    "    # Initialize bias for each layer  \n",
    "    \n",
    "    # did I ADd the bias wrong?\n",
    "    init_b_1 = np.random.randn(n_hidden_1).astype(theano.config.floatX)\n",
    "    init_b_2 = np.random.randn(n_hidden_2).astype(theano.config.floatX)\n",
    "    \n",
    "    with pm.Model() as neural_network:\n",
    "        # Weights from input to hidden layer\n",
    "        w_0_1 = pm.Normal('w_0_1', mu=0, sd=0.15, shape=(n_input, n_hidden_1), testval=init_w_1)\n",
    "        # Bias from in first layer\n",
    "        b_1 = pm.Normal('b_1',mu=0, sd=0.15, shape=(n_hidden_1), testval=init_b_1)\n",
    "        \n",
    "        # Weights from 1st to 2nd layer\n",
    "        w_1_2 = pm.Normal('w_1_2',mu=0, sd=0.15, shape=(n_hidden_1, n_hidden_2), testval=init_w_2)\n",
    "        # Bias from in first layer\n",
    "        b_2 = pm.Normal('b_2', mu=0, sd=0.15, shape=(n_hidden_2), testval=init_b_2)\n",
    "        \n",
    "        # Weights from hidden layer to output\n",
    "        w_2_out = pm.Normal('w_2_out', mu=0, sd=0.15,shape=(n_hidden_2,n_output),testval=init_out)\n",
    "        \n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.Deterministic('act_1',var=pm.math.tanh(pm.math.dot(ann_input,w_0_1)+b_1))\n",
    "        act_2 = pm.Deterministic('act_2',var=pm.math.tanh(pm.math.dot(act_1,w_1_2)+b_2))\n",
    "        \n",
    "        # Softmax is required at last layer\n",
    "        act_out = pm.Deterministic('act_out',var=tt.nnet.softmax(pm.math.dot(act_2,w_2_out)))\n",
    "        \n",
    "        # Classification\n",
    "        out = pm.Categorical('out',act_out,observed=ann_output,total_size=n_train)\n",
    "        \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We selected number of nodes/layers for fast performance\n",
    "n_hidden = 96\n",
    "net_name = \"Layer1: {}nodes\".format(n_hidden)\n",
    "\n",
    "minibatch_x = pm.Minibatch(X_train, batch_size=50)\n",
    "minibatch_y = pm.Minibatch(y_train, batch_size=50)\n",
    "\n",
    "(n_train,n_input) = X_train.shape\n",
    "NN_model = construct_nn_1lay(minibatch_x, minibatch_y, n_input, n_output, n_train, n_hidden_1=n_hidden)\n",
    "\n",
    "NN_model.name = net_name\n",
    "print(NN_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence not great, use a different method for conv check after:\n",
    "# https://docs.pymc.io/notebooks/variational_api_quickstart.html\n",
    "with NN_model:\n",
    "    advi = pm.ADVI()\n",
    "    \n",
    "# After the bayes by BackProp paper!\n",
    "print(advi.approx.shared_params)\n",
    "\n",
    "# To better look at convergence, we keep track of parameter mean and std\n",
    "ev_mean = advi.approx.mean.eval # callable that returns mean\n",
    "ev_std = advi.approx.std.eval # callable that returns std\n",
    "tracker = pm.callbacks.Tracker(mean=ev_mean,std=ev_std)\n",
    "print(tracker.whatchdict)\n",
    "\n",
    "n_approx_iter = 20000\n",
    "with NN_model:\n",
    "    approx = advi.fit(n=n_approx_iter, callbacks=[tracker])\n",
    "    # callbacks do not work for large numbers of iters on the network (>40k)\n",
    "    #approx = advi.fit(n=n_approx_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a reshape on a random subset might be more efficient here\n",
    "#tracker_means = np.array(tracker['mean'][randset])\n",
    "get_weight_mean = lambda i : [t[i] for t in tracker['mean']]\n",
    "get_weight_stds = lambda i : [t[i] for t in tracker['std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the training progress\n",
    "elbo_1 = -advi.hist\n",
    "\n",
    "figsize = (8,3); fontsize = 16;\n",
    "f, ax = plt.subplots(1,1,figsize=figsize);\n",
    "\n",
    "ax.plot(elbo_1,label='1')\n",
    "ax.set_ylabel('ELBO',fontsize=fontsize)\n",
    "ax.set_xlabel('iteration',fontsize=fontsize);\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (8,3); fontsize = 16;\n",
    "f, axs = plt.subplots(1,2,figsize=figsize)\n",
    "\n",
    "ax = axs[0]\n",
    "for i in range(30):\n",
    "    ax.plot(get_weight_stds(i),alpha=0.5,label=i)\n",
    "ax.set_xlabel('iteration',fontsize=fontsize);\n",
    "ax.set_title('std[weights]',fontsize=fontsize);\n",
    "sns.despine();\n",
    "\n",
    "ax = axs[1]\n",
    "for i in range(30):\n",
    "    ax.plot(get_weight_mean(i),alpha=0.5,label=i)\n",
    "ax.set_xlabel('iteration',fontsize=fontsize);\n",
    "ax.set_title('mean[weights]',fontsize=fontsize);\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for a few more samples if desired\n",
    "run_again = True\n",
    "if run_again:\n",
    "    advi.refine(n=20000);\n",
    "    elbo_2 = -advi.hist\n",
    "    \n",
    "    figsize = (8,3); fontsize = 16;\n",
    "    f, ax = plt.subplots(1,1,figsize=figsize);\n",
    "    ax.plot(elbo_2,label='elbo_2');\n",
    "    ax.set_ylabel('ELBO',fontsize=fontsize);\n",
    "    ax.set_xlabel('iteration',fontsize=fontsize);\n",
    "    sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw samples from variational posterior (the weights in the network)\n",
    "n_draws = 1000 # > 2k hangs for almost all network sizes on my 2018 MBP -SH\n",
    "trace = approx.sample(draws=n_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at training set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network at performance on the training set\n",
    "(n_train,n_input) = X_train.shape\n",
    "train_x = theano.shared(X_train)\n",
    "train_y = theano.shared(y_train)\n",
    "NN_model_train = construct_nn_1lay(train_x, train_y, n_input, n_output, n_train, n_hidden_1=n_hidden)\n",
    "with NN_model_train:\n",
    "    ppc_train = pm.sample_ppc(trace, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction is mode of each\n",
    "train_y_pred = mode(ppc_train['out'], axis=0).mode[0,:]\n",
    "\n",
    "mean_train_perf = np.mean(train_y_pred==y_train)\n",
    "print(\"Network Training Set Performance: {:f}\".format(mean_train_perf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network at performance on the test set\n",
    "(n_test,n_input) = X_test.shape\n",
    "test_x = theano.shared(X_test)\n",
    "test_y = theano.shared(y_test)\n",
    "NN_model_test = construct_nn_1lay(test_x, test_y, n_input, n_output, n_test, n_hidden_1=n_hidden)\n",
    "with NN_model_test:\n",
    "    ppc_test = pm.sample_ppc(trace, samples=100)\n",
    "    #ppc_test = pm.sample_posterior_predictive(trace, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims: [n_samples] x [n_test_set]\n",
    "ppc_test['out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = ppc_test['out'].shape[0]\n",
    "nrow = ppc_test['out'].shape[1]\n",
    "nhot = n_output\n",
    "onehot = np.zeros(shape=(ncol,nrow,nhot))\n",
    "for i in range(ncol):\n",
    "    onehot[i][np.arange(n_test), ppc_test['out'][i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction is mode of each\n",
    "test_y_pred = mode(ppc_test['out'], axis=0).mode[0,:]\n",
    "\n",
    "mean_test_perf = np.mean(test_y_pred==y_test)\n",
    "print(\"Network Test Set Performance: {:f}\".format(mean_test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot random subset of images\n",
    "n_plot_samples = 10\n",
    "rand_samps = np.random.choice(X_test.shape[0],size=n_plot_samples)\n",
    "\n",
    "figsize = (18,3); fontsize = 16;\n",
    "f, axs = plt.subplots(1, n_plot_samples, figsize=figsize);\n",
    "\n",
    "for rs,ax in zip(rand_samps,axs):\n",
    "    ax.imshow(imgvec2img(X_train[rs]),cmap='gray');\n",
    "    tl = \"{}: {},\\n{}: {}\".format(test_y_pred[rs],label_dict[test_y_pred[rs]],y_test[rs],label_dict[y_test[rs]])\n",
    "    if test_y_pred[rs] == y_test[rs]:\n",
    "        ax.set_title(tl,color='k');\n",
    "    else:\n",
    "        ax.set_title(tl,color='r');\n",
    "    ax.axis('off');\n",
    "    sns.despine();\n",
    "    \n",
    "f.suptitle(\"Example BBB Classification\",fontsize=fontsize+4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:am207]",
   "language": "python",
   "name": "conda-env-am207-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
